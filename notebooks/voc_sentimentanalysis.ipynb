{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce735f0",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610b21c",
   "metadata": {},
   "source": [
    "This notebook runs all models for sentiment analysis and show the results in terms of performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if you run into \"ModuleNotFoundError: No module named 'src'\"\n",
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# importing modules\n",
    "import transformations as c\n",
    "from sentiment_analysis.train.train_vader import train_vader\n",
    "from sentiment_analysis.train.train_textblob import train_textblob\n",
    "\n",
    "from sentiment_analysis.train.train_bert import *\n",
    "from sentiment_analysis.train.train_xgboost import train_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "current_path = os.getcwd()\n",
    "root_path = os.path.dirname(current_path)\n",
    "df = pd.read_csv(root_path + '/data/reviews.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a399f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data & add labels\n",
    "df['clean_text'] = df['Text'].apply(lambda x: c.get_cleantext(x))\n",
    "df['Sentiment_num'] = df.Sentiment.map({\"positive\": 1, \"negative\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train-test data\n",
    "X = df['clean_text'].to_list()\n",
    "y = df['Sentiment_num'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=4263\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "X_train_tf = tf_idf(X_train)\n",
    "X_train_word2vec = word2vec(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64586d0",
   "metadata": {},
   "source": [
    "## Vader & TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78acc4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run vader and textblob\n",
    "vader, vader_accuracy = train_vader(df)\n",
    "textblob, textblob_accuracy = train_textblob(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Accuracy\":[vader_accuracy, textblob_accuracy]})\n",
    "results.index = ['VADER', 'TextBlob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc33f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Accuracy'].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77972dad",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_bert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bac932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = initialise_bert(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = train_bert(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_trial.hyperparameters)\n",
    "res_dict['bert'] = best_trial.metrics['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026f780",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a80cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_estimator = train_xgboost(X_train_tf, X_train_word2vec, y_train, metric= \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407992b",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48762743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metrics for test data\n",
    "def model_comparison(best_train_estimator, X_test, y_test):\n",
    "    y_pred = best_train_estimator.predict(X_test)\n",
    "    # evalution metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\"\"Test accuracy is {}.\n",
    "             Test Recall is {}.\n",
    "             Test Precision is {}.\n",
    "             Test f1 score is {}\"\"\".format(acc, pre, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison(xgb_best_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe174a7",
   "metadata": {},
   "source": [
    "Justification for selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6a7af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
